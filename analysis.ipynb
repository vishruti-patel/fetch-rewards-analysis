{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef482a9-043c-40af-ab6a-8fbbac4c35e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading from a JSON file\n",
    "df_brands = pd.read_json('brands.json', lines=True)\n",
    "df = pd.json_normalize(df_brands.to_dict(orient='records'), sep='_')\n",
    "\n",
    "# df['createdDate_$date'] = pd.to_datetime(df['createdDate_$date'], unit='ms')\n",
    "# df['lastLogin_$date'] = pd.to_datetime(df['lastLogin_$date'], unit='ms')\n",
    "\n",
    "df\n",
    "# df_receipts = pd.read_json('receipts.json')\n",
    "# df_users = pd.read_json('users.json')\n",
    "\n",
    "# df_brands\n",
    "\n",
    "# {\n",
    "#     \"_id\": {\n",
    "#         \"$oid\": \"601ac115be37ce2ead437551\"\n",
    "#     },\n",
    "#     \"barcode\": \"511111019862\",\n",
    "#     \"category\": \"Baking\",\n",
    "#     \"categoryCode\": \"BAKING\",\n",
    "#     \"cpg\": {\n",
    "#         \"$id\": {\n",
    "#             \"$oid\": \"601ac114be37ce2ead437550\"\n",
    "#         },\n",
    "#         \"$ref\": \"Cogs\"\n",
    "#     },\n",
    "#     \"name\": \"test brand @1612366101024\",\n",
    "#     \"topBrand\": false\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "390f8108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Receipts Data:\n",
      "\n",
      "Receipt Items Data:\n",
      "        barcode                                        description finalPrice  \\\n",
      "0          4011                                     ITEM NOT FOUND      26.00   \n",
      "1          4011                                     ITEM NOT FOUND          1   \n",
      "2  028400642255  DORITOS TORTILLA CHIP SPICY SWEET CHILI REDUCE...      10.00   \n",
      "3           NaN                                                NaN        NaN   \n",
      "4          4011                                     ITEM NOT FOUND      28.00   \n",
      "\n",
      "  itemPrice needsFetchReview partnerItemId preventTargetGapPoints  \\\n",
      "0     26.00            False             1                   True   \n",
      "1         1              NaN             1                    NaN   \n",
      "2     10.00             True             2                   True   \n",
      "3       NaN            False             1                   True   \n",
      "4     28.00            False             1                   True   \n",
      "\n",
      "   quantityPurchased userFlaggedBarcode userFlaggedNewItem  ... itemNumber  \\\n",
      "0                5.0               4011               True  ...        NaN   \n",
      "1                1.0                NaN                NaN  ...        NaN   \n",
      "2                1.0       028400642255               True  ...        NaN   \n",
      "3                NaN               4011               True  ...        NaN   \n",
      "4                4.0               4011               True  ...        NaN   \n",
      "\n",
      "   originalMetaBriteQuantityPurchased pointsEarned targetPrice  \\\n",
      "0                                 NaN          NaN         NaN   \n",
      "1                                 NaN          NaN         NaN   \n",
      "2                                 NaN          NaN         NaN   \n",
      "3                                 NaN          NaN         NaN   \n",
      "4                                 NaN          NaN         NaN   \n",
      "\n",
      "  competitiveProduct originalFinalPrice originalMetaBriteItemPrice deleted  \\\n",
      "0                NaN                NaN                        NaN     NaN   \n",
      "1                NaN                NaN                        NaN     NaN   \n",
      "2                NaN                NaN                        NaN     NaN   \n",
      "3                NaN                NaN                        NaN     NaN   \n",
      "4                NaN                NaN                        NaN     NaN   \n",
      "\n",
      "  priceAfterCoupon metabriteCampaignId  \n",
      "0              NaN                 NaN  \n",
      "1              NaN                 NaN  \n",
      "2              NaN                 NaN  \n",
      "3              NaN                 NaN  \n",
      "4              NaN                 NaN  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Load and normalize users data\n",
    "# users_df = pd.read_json('users.json', lines=True)\n",
    "# users_df = pd.json_normalize(users_df.to_dict(orient='records'), sep='_')\n",
    "\n",
    "# #Display the data\n",
    "# # print(\"Users Data:\")\n",
    "# # users_df\n",
    "\n",
    "\n",
    "#Load and normalize brands data\n",
    "# brands_df = pd.read_json('brands.json', lines=True)\n",
    "# brands_df = pd.json_normalize(brands_df.to_dict(orient='records'), sep='_')\n",
    "\n",
    "# print(\"\\nbrands Data:\")\n",
    "# brands_df\n",
    "\n",
    "\n",
    "# with open(\"receipts.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     first_lines = [next(file) for _ in range(5)]  # Read first 5 lines\n",
    "#     print(first_lines)\n",
    "\n",
    "\n",
    "# # Load and normalize receipt data\n",
    "receipts_df = pd.read_json('receipts.json', lines=True)\n",
    "receipts_df = pd.json_normalize(receipts_df.to_dict(orient='records'), sep='_')\n",
    "print(\"\\nReceipts Data:\")\n",
    "receipts_df\n",
    "\n",
    "# print(receipts_df.head())  # Preview the flattened DataFrame\n",
    "\n",
    "\n",
    "# Expand 'rewardsReceiptItemList' into separate rows\n",
    "receipt_items_df = receipts_df.explode('rewardsReceiptItemList')\n",
    "receipt_items_df = pd.json_normalize(receipt_items_df['rewardsReceiptItemList'])\n",
    "\n",
    "# # Normalize nested fields\n",
    "# df = pd.json_normalize(\n",
    "#     receipts_df, \n",
    "#     record_path=['rewardsReceiptItemList'],  # Extract nested list\n",
    "#     meta=['_id', 'userId', 'totalSpent']  # Keep parent-level fields\n",
    "# )\n",
    "\n",
    "\n",
    "#Display the data\n",
    "# print(\"Users Data:\")\n",
    "# users_df\n",
    "\n",
    "\n",
    "print(\"\\nReceipt Items Data:\")\n",
    "print(receipt_items_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9190ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Receipt Items Data:\n",
      "        barcode                                        description finalPrice  \\\n",
      "0          4011                                     ITEM NOT FOUND      26.00   \n",
      "1          4011                                     ITEM NOT FOUND          1   \n",
      "2  028400642255  DORITOS TORTILLA CHIP SPICY SWEET CHILI REDUCE...      10.00   \n",
      "3           NaN                                                NaN        NaN   \n",
      "4          4011                                     ITEM NOT FOUND      28.00   \n",
      "\n",
      "  itemPrice needsFetchReview partnerItemId preventTargetGapPoints  \\\n",
      "0     26.00            False             1                   True   \n",
      "1         1              NaN             1                    NaN   \n",
      "2     10.00             True             2                   True   \n",
      "3       NaN            False             1                   True   \n",
      "4     28.00            False             1                   True   \n",
      "\n",
      "   quantityPurchased userFlaggedBarcode userFlaggedNewItem  ... itemNumber  \\\n",
      "0                5.0               4011               True  ...        NaN   \n",
      "1                1.0                NaN                NaN  ...        NaN   \n",
      "2                1.0       028400642255               True  ...        NaN   \n",
      "3                NaN               4011               True  ...        NaN   \n",
      "4                4.0               4011               True  ...        NaN   \n",
      "\n",
      "   originalMetaBriteQuantityPurchased pointsEarned targetPrice  \\\n",
      "0                                 NaN          NaN         NaN   \n",
      "1                                 NaN          NaN         NaN   \n",
      "2                                 NaN          NaN         NaN   \n",
      "3                                 NaN          NaN         NaN   \n",
      "4                                 NaN          NaN         NaN   \n",
      "\n",
      "  competitiveProduct originalFinalPrice originalMetaBriteItemPrice deleted  \\\n",
      "0                NaN                NaN                        NaN     NaN   \n",
      "1                NaN                NaN                        NaN     NaN   \n",
      "2                NaN                NaN                        NaN     NaN   \n",
      "3                NaN                NaN                        NaN     NaN   \n",
      "4                NaN                NaN                        NaN     NaN   \n",
      "\n",
      "  priceAfterCoupon metabriteCampaignId  \n",
      "0              NaN                 NaN  \n",
      "1              NaN                 NaN  \n",
      "2              NaN                 NaN  \n",
      "3              NaN                 NaN  \n",
      "4              NaN                 NaN  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# # Load and normalize users data\n",
    "# users_df = pd.read_json('users.json', lines=True)\n",
    "# users_df = pd.json_normalize(users_df.to_dict(orient='records'), sep='_')\n",
    "\n",
    "# # Load and normalize brands data\n",
    "# brands_df = pd.read_json('brands.json', lines=True)\n",
    "# brands_df = pd.json_normalize(brands_df.to_dict(orient='records'), sep='_')\n",
    "\n",
    "\n",
    "# # Load and normalize receipt data\n",
    "# receipts_df = pd.read_json('receipts.json', lines=True)\n",
    "# receipts_df = pd.json_normalize(receipts_df.to_dict(orient='records'), sep='_')\n",
    "\n",
    "# # Expand 'rewardsReceiptItemList' into separate rows\n",
    "# receipt_items_df = receipts_df.explode('rewardsReceiptItemList')\n",
    "# receipt_items_df = pd.json_normalize(receipt_items_df['rewardsReceiptItemList'])\n",
    "\n",
    "# # Display the data\n",
    "# print(\"Users Data:\")\n",
    "# print(users_df.head())\n",
    "\n",
    "# print(\"\\nbrands Data:\")\n",
    "# print(brands_df.head())\n",
    "\n",
    "# print(\"\\nReceipts Data:\")\n",
    "# print(receipts_df.head())\n",
    "\n",
    "# print(\"\\nReceipt Items Data:\")\n",
    "# print(receipt_items_df.head())\n",
    "\n",
    "\n",
    "# Load receipts data\n",
    "with open(\"receipts.json\", \"r\") as file:\n",
    "    receipts_data = [json.loads(line) for line in file]\n",
    "\n",
    "receipts_df = pd.DataFrame(receipts_data)\n",
    "\n",
    "# Load brands data\n",
    "with open(\"brands.json\", \"r\") as file:\n",
    "    brands_data = [json.loads(line) for line in file]\n",
    "\n",
    "brands_df = pd.DataFrame(brands_data)\n",
    "\n",
    "# Convert `dateScanned` to datetime\n",
    "receipts_df[\"dateScanned\"] = pd.to_datetime(receipts_df[\"dateScanned\"].apply(lambda x: x[\"$date\"]), unit=\"ms\")\n",
    "\n",
    "# Get the most recent month\n",
    "most_recent_month = receipts_df[\"dateScanned\"].max().strftime(\"%Y-%m\")\n",
    "\n",
    "# Filter receipts for the most recent month\n",
    "filtered_receipts = receipts_df[receipts_df[\"dateScanned\"].dt.strftime(\"%Y-%m\") == most_recent_month]\n",
    "\n",
    "# Extract brand counts from the receipts\n",
    "brand_counts = filtered_receipts.explode(\"rewardsReceiptItemList\")  # Expand list items\n",
    "brand_counts[\"brandId\"] = brand_counts[\"rewardsReceiptItemList\"].apply(lambda x: x.get(\"rewardsProductPartnerId\") if isinstance(x, dict) else None)\n",
    "\n",
    "# Count receipts per brand\n",
    "top_brands = brand_counts[\"brandId\"].value_counts().head(5).reset_index()\n",
    "top_brands.columns = [\"brandId\", \"receipt_count\"]\n",
    "\n",
    "# Merge with brand names\n",
    "top_brands = top_brands.merge(brands_df[[\"_id\", \"brandName\"]], left_on=\"brandId\", right_on=\"_id\", how=\"left\")\n",
    "\n",
    "# Select relevant columns\n",
    "top_brands = top_brands[[\"brandName\", \"receipt_count\"]]\n",
    "\n",
    "print(top_brands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a0bd68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    _id  bonusPointsEarned  \\\n",
      "0  {'$oid': '5ff1e1eb0a720f0523000575'}              500.0   \n",
      "1  {'$oid': '5ff1e1bb0a720f052300056b'}              150.0   \n",
      "2  {'$oid': '5ff1e1f10a720f052300057a'}                5.0   \n",
      "3  {'$oid': '5ff1e1ee0a7214ada100056f'}                5.0   \n",
      "4  {'$oid': '5ff1e1d20a7214ada1000561'}                5.0   \n",
      "\n",
      "                             bonusPointsEarnedReason  \\\n",
      "0  Receipt number 2 completed, bonus point schedu...   \n",
      "1  Receipt number 5 completed, bonus point schedu...   \n",
      "2                         All-receipts receipt bonus   \n",
      "3                         All-receipts receipt bonus   \n",
      "4                         All-receipts receipt bonus   \n",
      "\n",
      "                 createDate               dateScanned  \\\n",
      "0  {'$date': 1609687531000}  {'$date': 1609687531000}   \n",
      "1  {'$date': 1609687483000}  {'$date': 1609687483000}   \n",
      "2  {'$date': 1609687537000}  {'$date': 1609687537000}   \n",
      "3  {'$date': 1609687534000}  {'$date': 1609687534000}   \n",
      "4  {'$date': 1609687506000}  {'$date': 1609687506000}   \n",
      "\n",
      "               finishedDate                modifyDate  \\\n",
      "0  {'$date': 1609687531000}  {'$date': 1609687536000}   \n",
      "1  {'$date': 1609687483000}  {'$date': 1609687488000}   \n",
      "2                       NaN  {'$date': 1609687542000}   \n",
      "3  {'$date': 1609687534000}  {'$date': 1609687539000}   \n",
      "4  {'$date': 1609687511000}  {'$date': 1609687511000}   \n",
      "\n",
      "          pointsAwardedDate  pointsEarned              purchaseDate  \\\n",
      "0  {'$date': 1609687531000}         500.0  {'$date': 1609632000000}   \n",
      "1  {'$date': 1609687483000}         150.0  {'$date': 1609601083000}   \n",
      "2                       NaN           5.0  {'$date': 1609632000000}   \n",
      "3  {'$date': 1609687534000}           5.0  {'$date': 1609632000000}   \n",
      "4  {'$date': 1609687506000}           5.0  {'$date': 1609601106000}   \n",
      "\n",
      "   purchasedItemCount                             rewardsReceiptItemList  \\\n",
      "0                 5.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "1                 2.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "2                 1.0  [{'needsFetchReview': False, 'partnerItemId': ...   \n",
      "3                 4.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "4                 2.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "\n",
      "  rewardsReceiptStatus  totalSpent                    userId  \n",
      "0             FINISHED        26.0  5ff1e1eacfcf6c399c274ae6  \n",
      "1             FINISHED        11.0  5ff1e194b6a9d73a3a9f1052  \n",
      "2             REJECTED        10.0  5ff1e1f1cfcf6c399c274b0b  \n",
      "3             FINISHED        28.0  5ff1e1eacfcf6c399c274ae6  \n",
      "4             FINISHED         1.0  5ff1e194b6a9d73a3a9f1052  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_json(\"receipts.json\", lines=True)\n",
    "print(df.head())\n",
    "\n",
    "# # Read the raw JSON file\n",
    "# with open(\"receipts.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     data = json.load(file)  # Load the JSON file as a dictionary/list\n",
    "\n",
    "# # Print the first item to inspect its structure\n",
    "# print(json.dumps(data[0], indent=2))\n",
    "\n",
    "# # Function to clean MongoDB-style JSON\n",
    "# def clean_mongo_json(obj):\n",
    "#     if isinstance(obj, dict):  # If it's a dictionary\n",
    "#         if \"$oid\" in obj:  # Convert MongoDB ObjectId to a string\n",
    "#             return obj[\"$oid\"]\n",
    "#         elif \"$date\" in obj:  # Convert MongoDB Date to a readable format\n",
    "#             return pd.to_datetime(obj[\"$date\"], unit=\"ms\")  # Convert timestamp to datetime\n",
    "#         else:\n",
    "#             return {k: clean_mongo_json(v) for k, v in obj.items()}  # Recursively clean\n",
    "#     elif isinstance(obj, list):  # If it's a list, clean each element\n",
    "#         return [clean_mongo_json(i) for i in obj]\n",
    "#     else:\n",
    "#         return obj  # Return as is if it's not a dict or list\n",
    "\n",
    "# # Apply cleaning function to the entire dataset\n",
    "# cleaned_data = clean_mongo_json(data)\n",
    "\n",
    "\n",
    "\n",
    "# # Convert cleaned JSON to DataFrame\n",
    "# df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "# # Print sample rows\n",
    "# print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a51cecc",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 2 column 1 (char 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33mreceipts.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     data = \u001b[43m[\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Read line by line\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[32m     11\u001b[39m df = pd.DataFrame(data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      5\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33mreceipts.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     data = [\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file]  \u001b[38;5;66;03m# Read line by line\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[32m     11\u001b[39m df = pd.DataFrame(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.2/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.2/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.2/lib/python3.11/json/decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \n\u001b[32m    351\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 2 column 1 (char 9)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON file as line-delimited JSON\n",
    "file_path = \"receipts.json\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]  # Read line by line\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02acfcf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 16 column 1 (char 941)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m output_file_path = \u001b[33m'\u001b[39m\u001b[33mreceipts_converted.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Process the file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mprocess_json_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConversion completed. The output is saved in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mreceipts_converted.json\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mprocess_json_file\u001b[39m\u001b[34m(input_file_path, output_file_path)\u001b[39m\n\u001b[32m     39\u001b[39m processed_data = preprocess_json(input_file_path)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Load the data from the preprocessed content\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Convert each record in the data to the standard JSON format\u001b[39;00m\n\u001b[32m     45\u001b[39m converted_data = [convert_mongodb_to_standard(record) \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.2/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.2/lib/python3.11/json/decoder.py:340\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 16 column 1 (char 941)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to replace single quotes with double quotes and fix other issues\n",
    "def preprocess_json(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile:\n",
    "        data = infile.read()\n",
    "        \n",
    "    # Replace single quotes with double quotes for keys and string values\n",
    "    data = re.sub(r\"(?<=[:\\[,])\\s*'(.*?)'\\s*(?=\\s*[:,\\]\\}])\", r'\"\\1\"', data)\n",
    "    # Ensure double quotes for the keys and string values, and remove any extra commas at the end of objects/arrays\n",
    "    data = re.sub(r\"(?<=[:\\[,])\\s*'(.*?)'\\s*(?=\\s*[:,\\]\\}])\", r'\"\\1\"', data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function to convert MongoDB-specific fields to standard JSON format\n",
    "def convert_mongodb_to_standard(json_data):\n",
    "    # Recursively process the data\n",
    "    if isinstance(json_data, dict):\n",
    "        # If the dictionary contains \"$oid\", convert it to a string\n",
    "        if \"$oid\" in json_data:\n",
    "            return str(json_data[\"$oid\"])\n",
    "        # If the dictionary contains \"$date\", convert it to ISO 8601 format\n",
    "        if \"$date\" in json_data:\n",
    "            return datetime.utcfromtimestamp(json_data[\"$date\"] / 1000).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        # Process each key-value pair recursively\n",
    "        return {key: convert_mongodb_to_standard(value) for key, value in json_data.items()}\n",
    "    elif isinstance(json_data, list):\n",
    "        # If it's a list, recursively process each item\n",
    "        return [convert_mongodb_to_standard(item) for item in json_data]\n",
    "    else:\n",
    "        # Return the data as is if it's not a dictionary or list\n",
    "        return json_data\n",
    "\n",
    "# Function to process the entire JSON file\n",
    "def process_json_file(input_file_path, output_file_path):\n",
    "    # Preprocess the input file to ensure valid JSON format\n",
    "    processed_data = preprocess_json(input_file_path)\n",
    "    \n",
    "    # Load the data from the preprocessed content\n",
    "    data = json.loads(processed_data)\n",
    "    \n",
    "    # Convert each record in the data to the standard JSON format\n",
    "    converted_data = [convert_mongodb_to_standard(record) for record in data]\n",
    "    \n",
    "    # Write the converted data to the output JSON file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(converted_data, outfile, indent=4)\n",
    "\n",
    "# Input and output file paths\n",
    "input_file_path = 'receipts.json'\n",
    "output_file_path = 'receipts_converted.json'\n",
    "\n",
    "# Process the file\n",
    "process_json_file(input_file_path, output_file_path)\n",
    "\n",
    "print(\"Conversion completed. The output is saved in 'receipts_converted.json'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
